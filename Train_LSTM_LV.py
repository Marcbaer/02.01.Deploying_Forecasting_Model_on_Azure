'''
LSTM regression on Lotka Volterra System 
'''
import numpy as np
import pickle
import matplotlib.pyplot as plt

#Keras imports
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import ModelCheckpoint
#from sklearn.model_selection import StratifiedKFold

seed=1
np.random.seed(seed)

#training parameters
shift=1
sequence_length=12
pred_mode=1

def load_data(shift,pred_mode,sequence_length):
    '''
    Load Lotka-Volterra Data (generated by the script Lotka_volterra_data.py)
    and create input sequences and training data.

    Parameters
    ----------
    shift : Integer
        Number of steps to be predicted into the future.
    pred_mode : Integer
        Mode to be forecasted, Predator or Pray population.
    sequence_length: Integer
        Window size provided as input.
    Returns
    -------
    data : Dictionnary
        Training data splitted into train, test and validation set.
    '''    
    #shift =1 for one step ahead prediction
    total_length=sequence_length+shift
    sample_size=2000

    data = pickle.load(open("./Data/Lotka_Volterra2.p", "rb"))

    #create sequences with length sequence_length
    result = []
    for index in range(len(data) - total_length):
        
        i=data[index: index + total_length]
        k=i[:sequence_length]
        j=np.array(i[total_length-1])
        j=j.reshape(1,2)
        k=np.append(k,j,axis=0)
        result.append(k)
        
    result = np.array(result) 
    
    #reshape (#Timesteps,seq_length,#modes)
    
    result=result.reshape(result.shape[0],result.shape[1],2)
    
    train_end=int(0.8*len(result))
    res_train=result[:train_end]
    res_test=result[train_end:]

    #sample_size
    valid=int(0.8*sample_size)
    Input_data=res_train[:sample_size,:sequence_length,:]
    #Output_data=res_train[:sample_size,-1,pred_mode-1]
    Output_data=res_train[:sample_size,-1,:]
    
    Input_data_test=res_test[:int(sample_size/3),:sequence_length,:]
    #Output_data_test=res_test[:int(sample_size/3),-1,pred_mode-1]  
    Output_data_test=res_test[:int(sample_size/3),-1,:]  
    X_train=Input_data[:valid,:,:]
    y_training=Output_data[:valid]
    
    X_test=Input_data_test[:,:]
    y_testing=Output_data_test[:]
    
    X_valid=Input_data[valid:,:,:]
    y_validation=Output_data[valid:] 
    
    #Reshape targets
    
    y_train=y_training.reshape(y_training.shape[0],2)
    y_test=y_testing.reshape(y_testing.shape[0],2)
    y_valid=y_validation.reshape(y_validation.shape[0],2)
    
    
    data = {
        'train': [X_train, y_train],
        'valid': [X_valid, y_valid],
        'test': [X_test, y_test],
    }
    
    return data

if __name__ == '__main__':
    #Load Data
    data=load_data(shift,pred_mode,sequence_length)
    
    #Build and Train LSTM
    #Define model parameters
    n_features=2
    n_steps=12
    
    # define model
    checkpoint = ModelCheckpoint('best_LV_LSTM.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  
    
    model = Sequential()
    model.add(LSTM(6, activation='relu', input_shape=(n_steps, n_features)))
    model.add(Dense(2))
    model.compile(optimizer='adam', loss='mse')
    
    # fit model
    history = model.fit(data['train'][0], data['train'][1],validation_data=(data['valid'][0], data['valid'][1]), epochs=250, verbose=2,callbacks=[checkpoint])
    
    # demonstrate prediction
    x_input = data['test'][0][0]
    x_input = x_input.reshape((1, n_steps, n_features))
    yhat = model.predict(x_input, verbose=0)
    print('predicted:',yhat)
    print('target:',data['test'][1][0])
    
    # Generate generalization metrics
    score = model.evaluate(data['test'][0], data['test'][1], verbose=1)
    print(f'Test loss: {score}')
    
    # Visualize training history
    plt.plot(history.history['val_loss'],label='Validation Loss')
    plt.plot(history.history['loss'],label='Training Loss')
    plt.title('Validation loss history')
    plt.ylabel('Loss value')
    plt.xlabel('No. epoch')
    plt.legend(loc=1)
    plt.show()












